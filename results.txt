Deep Belief Networks consist multiple layers, a hierarchy of 
unsupervised Restricted Boltzmann Machines (RBMs) where the 
output of each RBM is used as input to the next.
And then supervised back-propagation step for fine-tuning

Dataset = MNIST
Learning Rate = 0.1
Epochs = 20
Number of Hidden Layers = 3
Number of Units Per Hidden Layer = 300


         digit   precision    recall  f1-score   support

          0       0.99      0.99      0.99      2258
          1       0.99      0.99      0.99      2615
          2       0.98      0.99      0.98      2333
          3       0.98      0.98      0.98      2385
          4       0.99      0.98      0.99      2239
          5       0.98      0.97      0.98      2026
          6       0.98      0.99      0.99      2247
          7       0.99      0.99      0.99      2453
          8       0.98      0.98      0.98      2280
          9       0.98      0.98      0.98      2264

avg / total       0.98      0.98      0.98     23100

Note that average Precision reached was 98% , whereas precision for 0,1,4,7 is typically high around 99%.